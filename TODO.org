* mysteries
** sisyphus gets in bad state with rabbit when a task fails
** it seems that one has to launch the workers, then wait for them to be ready, and only then trigger the workflow, otherwise trigger() doesn't start it
** a parca task never got picked up by a worker
** the Simulation task failed trying to delete the output directory:
*** Device or resource busy: '/wcEcoli/out/wf/wildtype_000000/000000/generation_000000/000000/simOut/'
** why do the worker VMs print "*** System restart required ***" when you ssh in?
* questions / considerations
** are there rules programmers need to know about tasks deleting and writing into the output directories?
** is it necessary to have running workers before flow.trigger() will work?
** probably need worker nodes with more RAM and disk space; maybe configurable
** reevaluate the worker shutdown rules or at least lengthen the worker timeout. if you start 3 worker nodes for WCM, 2 will take the para and write-json tasks, then the parca task takes so long that the write-json worker gives up. Maybe workers should stick around while jobs are running, or maybe we just need to auto-start more of them on demand and make them start up faster.
*** Yeah, it looks like we will ultimately need some kind of automatic launching, probably mediated by Gaia.
** worker nodes need to be robust to task failures
** the queue needs to be robust to task failures; don't rerun them unless that has a reasonable chance of working and there's a max number of retries; the rabbit interaction is failing on error in sisyphus
** auto-launch worker nodes
** store archive with .tgz suffix
** rename 'key' to 'name'? or to '_name' and use sorted key printouts (e.g. via pprint) so the _name shows up first (which is where you need it)
** do we need separate pyenv-virtualenvs to share a gateway machine or to gracefully handle updates?
** compare cloud shell to a gateway GCE instance
** use a docker image version tag? how to feed it to the workflow builder?
* sisyphus
** create intermediate directory entries in object store for nested keys
*** This seems to happen already? At least, when I upload something to a nested dir I can still access from the web browser.
** support relative local paths within the container (or reject them up front with a clear error message rather than failing obscurely)
** auto-create the output bucket?
* gaia
** the sisyphus VM needs more disk space (Could not setup log file in /home/sisyphus/.config/gcloud/logs, (OSError: [Errno 28] No space left on device: '/home/sisyphus/.config/gcloud/logs/2019.07.03'))
** document how to create the gaia and sisyphus VM images
** document how to restart and monitor the gaia and sisyphus servers
** the namespace should be independent of the bucket name
** put commands in namespace
** make a Gaia client pip and add it to the wcEcoli requirements, or something
** clean up each workflow job when done
** replace any yaml.load() calls with yaml.safe_load()
* logs (for now, the logs are the UI)
** log a message when a workflow stops running and indicate whether all tasks completed successfully
** ^C out of flow.listen() should not print a bunch of clutter in ipython
** store timestamp, sisyphus id in logs
** almost always filter logs for a specific job (= user + timestamp)
** sometimes filter logs for a specific task within a job
** design Gaia and Sisyphus logs [both for journalctl and flow.listen()] to be more informative, less cluttered, and easier to read
** clearly label the action for every log entry
** clearly label the error messages
** design the content of each message, e.g.
*** sisyphus-status: {u'status': u'create', u'docker-id': u'8441243d6973', u'id': u'cbb31409-3bc9-4811-94d0-97a0f6bfa3b5', u'docker-config': {u'mounts': {u'/tmp/sisyphus/outputs/data/jerry/20190701.110950/kb': u'/wcEcoli/out/wf/kb'}, u'image': u'gcr.io/allen-discovery-center-mcovert/jerry-wcm-code:latest', u'command': [u'sh', u'-c', u'python -u -m wholecell.fireworks.runTask parca \'{"ribosome_fitting": true, "rnapoly_fitting": true, "cpus": 1, "output_directory": "/wcEcoli/out/wf/kb/"}\'']}}
**** should be more like
*** worker sisyphus-b: python -u -m wholecell.fireworks.runTask parca {"ribosome_fitting": true, "rnapoly_fitting": true, "cpus": 1, "output_directory": "/wcEcoli/out/wf/kb/"}
**** and
*** sisyphus-log: {u'status': u'log', u'line': u'Fitting RNA synthesis probabilities.', u'id': u'cbb31409-3bc9-4811-94d0-97a0f6bfa3b5'}
**** should be more like
*** worker sisyphus-b: Fitting RNA synthesis probabilities.
** filter by job and optionally by task name or name pattern
** each job should have its own kafka topic(s) for logging, etc.
** perhaps flow.listen() should tune in at the start of the job or from where listen left off
** remove internal debugging messages
** label each message for its purpose
** remove the u'text' clutter
** adjustable logging levels
** streamline or strip out JSON data, UUIDs, and such except where it's definitely useful for debugging
** ideally, make a single log entry for a stack traceback
** adjust Kafka if possible to deliver log entries in smaller batches
** support stackdriver logging and filtering?
* errors
** return the error info (e.g. there's no storage bucket named "robin1") rather than hitting json-decoder-error trying to decode a POST response from the Gaia server
** need more error detection & reporting
** test what happens when things go wrong. does it emit helpful error messages? can it do self-repair?
* optimization
** how come it takes (at least sometimes) many minutes for workers to start picking up tasks?
** tasks run very slowly. do we need VMs with faster CPUs? more RAM? more cores? GPUs? larger disk?
** the log output comes out in batches of lines with many minutes between them
** optimization: reuse a running docker container when the previous task requested the same image
** optimization?: a separate set of nodes for each job
* documentation
** document all the GCE VM setup factors: machine type? boot disk size? OS? Identity and API access? additional access scopes? label e.g. `role=home-base`? startup script? metadata, e.g. configuration for accessing the other servers?
** write a step-by-step how-to document for lab members
*** setting the "sisyphus" service account when configuring the GCE instance works, which obviates all the activate-service-account steps
* features
** unit tests
** ability to post a workflow directly from your desktop?
** tools to simplify and speed up the dev cycle
** implement nightly builds and PR builds
** need DNS names within the cloud rather than hardwired IP addresses
** remote uploading to Gaia
** remote log monitoring
** remove webserver state viewing
* DONE
** Sisyphus created empty directories rather than storing archive files for WCM task outputs e.g. sisyphus/data/jerry/20190628.204402/kb/
** Sisyphus created directories for failed tasks e.g. sisyphus/data/jerry/20190628.204402/plotOut/
** pass an array of CLI tokens to Docker so the client doesn't have to do complex shell quoting (jerry put quoting into the WCM workflow as a temporary workaround) (maybe drop the unused && and > features)
** flow.trigger('sisyphus') gave a json error
** Sisyphus wrote outputs to GCS after some failed tasks, so retrying the same task names won't start
** WCM output .tgz archives aren't getting stored in GCS; only directory entries are stored
** clear output directories between task runs
** ensure that running a Command always begins without previous output files even if it reuses an open docker container
